{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32d3d186-5181-4b12-84f4-f1adaaffaba7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Multilayer perceptron classifier for news sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fa7da50-a107-4c29-9384-99a0e2f3705e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The financial news sentiment dataset has about 4846 records of financial news and corresponinding sentiment. The sentiments include 'positive', 'neutral' and 'negative'. \n",
    "The below code will load, precess data and use the mulilayer perceptron ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5f09033-1ad9-4603-8e25-b0be52dca6e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create a spark session and load the Financial News Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71a5807-e20d-4ac7-89f9-ad76debd9239",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48c9eb49-ac78-43f0-9ebd-b4260736621d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('FinancialNewsDL').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f34ee587-179e-492b-93a5-04024394870e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "\n",
    "file_location = \"/FileStore/finalproject/FinancialNewsSentiment.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "df_news = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\\\n",
    "\n",
    "#end loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7414b377-d910-4d72-8a05-e8998d7f6a1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_news = df_news.withColumnRenamed(\"_c0\",\"label\")\n",
    "df_news = df_news.withColumnRenamed(\"_c1\",\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaff8b80-bdb1-43cf-aad3-42ffd4c7925d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e48a15b-f3fb-42a8-9db7-b61d14221ee0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_news = df_news.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa801fa3-bedb-4fa0-b8cf-212f46d58e72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a 70-30 train test split\n",
    "\n",
    "train_data,test_data=df_news.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd886888-ddd0-43c8-b9d2-dc8d49928800",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Building the MultiLayerPerceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34b6824b-9a25-4982-9677-98a3084faa1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ac14a7b-7e60-495e-9536-6ba3ff33b61d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Index label column as it is category variable - positive, negative, neutral\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "labelIndexer = StringIndexer(inputCol=\"label\",outputCol=\"indexedLabel\")\n",
    "#labelIndexer = labelIndexer.fit(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4415472-910e-49d2-aeae-cc4ec5474ed2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"news\", outputCol=\"words\")\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures= 4000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06444c7e-e3fc-44e1-b152-1bd889fec7b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d8417a-236f-4323-b297-4d238aa281c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an object for the MultilayerPerception model\n",
    "\n",
    "layers = [4000,128,64,3]\n",
    "mlpModel = MultilayerPerceptronClassifier(maxIter=50, layers= layers, seed=1984, blockSize=128, featuresCol=\"features\", labelCol= \"indexedLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe73647-d806-4792-83bc-88e78081ada2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline is used to pass the data through indexer, tokenizer, TF-IDF simultaneously. Also, it helps to pre-rocess the test data in the same way as that of the train data. It also \n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipe = Pipeline(stages=[labelIndexer,tokenizer,hashingTF,idf,mlpModel])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67aea2a2-5c9f-4f82-8dcb-956f83831bb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fit_model=pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce3a0b9-d82b-41f9-baf1-1fdfc4d560b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Store the results in a dataframe\n",
    "\n",
    "result = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed304d1-feef-4d77-918c-1cc7c5b5698f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n|indexedLabel|prediction|\n+------------+----------+\n|         2.0|       2.0|\n|         2.0|       2.0|\n|         2.0|       0.0|\n|         2.0|       2.0|\n|         2.0|       2.0|\n|         2.0|       1.0|\n|         2.0|       0.0|\n|         2.0|       2.0|\n|         2.0|       2.0|\n|         2.0|       1.0|\n|         2.0|       0.0|\n|         2.0|       1.0|\n|         2.0|       0.0|\n|         2.0|       2.0|\n|         2.0|       2.0|\n|         2.0|       0.0|\n|         2.0|       1.0|\n|         2.0|       2.0|\n|         2.0|       2.0|\n|         2.0|       0.0|\n+------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "result.select(\"indexedLabel\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9978a1e6-7a96-494a-b2d9-57f21563352b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf5bba6b-65bf-48d4-a99f-7f34fbc65555",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15e7dcea-daf3-40ec-90f1-acf4a8879418",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.713487071977638\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "pred_and_actual = result.select(\"prediction\",\"indexedLabel\").withColumnRenamed(\"indexedLabel\",\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"The accuracy of the model is {}\".format(evaluator.evaluate(pred_and_actual)))\n",
    "#print(str(evaluator.evaluate(pred_and_actual)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31a0e502-2759-49e4-bcfa-7a3a8f2ac513",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb7e4c1-b3f1-4672-8983-86f9e4519685",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix \n [[688. 134.  33.]\n [143. 228.  27.]\n [ 43.  30. 105.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "#important: need to cast to float type, and order by prediction, else it won't work\n",
    "pred_and_actual = result.select(['prediction','indexedLabel']).withColumn('label', f.col('indexedLabel').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "pred_and_actual = pred_and_actual.select(['prediction','label'])\n",
    "\n",
    "metrics = MulticlassMetrics(pred_and_actual.rdd.map(tuple))\n",
    "\n",
    "#print(metrics.confusionMatrix().toArray())\n",
    "print(\"Below is the confusion matrix \\n {}\".format(metrics.confusionMatrix().toArray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "609f3b93-0bc3-48f5-aac2-7a023b436ac0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####  Area under the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3453de22-81fd-4bab-8571-99c30f532adc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the curve is 0.7501949317738792\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='indexedLabel',metricName='areaUnderROC')\n",
    "AUC = AUC_evaluator.evaluate(result)\n",
    "print(\"The area under the curve is {}\".format(AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d47eb93e-1f73-479c-9e8d-c78c0c1a251b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A roughly 75% area under ROC denotes the model has performed reasonably well in predicting the sentiment of financial news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67dca817-4471-474a-a7af-f1266e1440d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####  Area under the PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06e47acc-08b8-4512-80b7-42994293718b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the PR curve is 0.697350379579132\n"
     ]
    }
   ],
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='indexedLabel',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(result)\n",
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2f4f506-3d94-4834-a313-fbcf757e4014",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc0de231-e882-42d7-a965-b7952670c888",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#set / load basePath\n",
    "basePath = \"/FileStore/finalproject\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5e3fb14-8afb-4571-84b8-995a04d4e502",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Save the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba205cc3-1387-4231-b49f-6f933ece2349",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipe.write().overwrite().save(basePath + \"/pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1315bc0-cb76-4926-b721-5c32aff9c9c7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Save trained model (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdd7d70-09a5-42b5-a722-f057792e4aef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fit_model.write().overwrite().save(basePath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1ba4c3e-4959-45e9-9b3c-bfea54d14d37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load Model for new prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3280546e-9c93-49d9-b720-fc947b0b959f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Load / set basePath\n",
    "basePath = \"/FileStore/finalproject\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb6eef75-f99d-4031-ac99-79f51859c984",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Load the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e3ef51f-a6ab-48aa-992f-add9df3ca7ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipe_new = Pipeline.load(basePath + \"/pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40648c3c-f92d-4c2e-9e03-36e37cd9215e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Load the trained model (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e12bd4-bd1b-45a1-b2e3-74cc95d42b87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "load_fit_model = PipelineModel.load(basePath + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec3edea6-1a40-4412-b262-6c4c5c231dbb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Test Loading trained model. To be removed in the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e1b054-f7e5-4d71-a02c-cf0ce744dd01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_result = load_fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df30a88-4279-4e5f-b657-cbcb7fb31194",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.713487071977638\n"
     ]
    }
   ],
   "source": [
    "pred_and_actual = new_result.select(\"prediction\",\"indexedLabel\").withColumnRenamed(\"indexedLabel\",\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"The accuracy of the model is {}\".format(evaluator.evaluate(pred_and_actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23a518f5-d275-4611-abe3-171b46278f91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the confusion matrix \n [[688. 134.  33.]\n [143. 228.  27.]\n [ 43.  30. 105.]]\n"
     ]
    }
   ],
   "source": [
    "pred_and_actual = new_result.select(['prediction','indexedLabel']).withColumn('label', f.col('indexedLabel').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "pred_and_actual = pred_and_actual.select(['prediction','label'])\n",
    "\n",
    "metrics = MulticlassMetrics(pred_and_actual.rdd.map(tuple))\n",
    "\n",
    "#print(metrics.confusionMatrix().toArray())\n",
    "print(\"Below is the confusion matrix \\n {}\".format(metrics.confusionMatrix().toArray()))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "News_sentiment_modelling_v3",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
